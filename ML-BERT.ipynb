{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"Ek3QQMaUtmGJ"},"source":["#Import"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6167,"status":"ok","timestamp":1687519582724,"user":{"displayName":"林宥騰","userId":"01208095819161324571"},"user_tz":-480},"id":"YmCApsiA0gIC","outputId":"756949cf-ee58-43a1-ec4c-8bc022dc764e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m105.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m107.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n","\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RCZVmfnYnKrR"},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","from sklearn.model_selection import train_test_split\n","from transformers import BertTokenizer\n","\n","import json\n","import numpy as np\n","import pandas as pd"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"c_Z5sU9ytqiC"},"source":["# Data Prepare"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"bebBlGKxisLY"},"source":["## One Hot Encoding\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wyho5-AXVtYw"},"outputs":[],"source":["def OneHotEncoding(label):\n","  # get label without one-hot-encoding\n","  y_data = []\n","  for i in label:\n","    if '{' in i:\n","      a = json.loads(i)\n","      y_data.append(a['choices'])\n","    else:\n","      y_data.append(i)\n","\n","  # the top 5 most frequently label\n","  top5 = ['課業', '蓋樓', '生活', '問題', '食物']\n","\n","  # merge simliar label\n","  sim_to_edu = ['考試', '選課']\n","  sim_to_live = ['遊戲', '天氣', '宿舍', '疫情', '動漫', '假期', '活動', '拔', '節日']\n","\n","  for idx, i in enumerate(y_data):\n","    if type(i) is list:\n","      for idx_i, j in enumerate(i):\n","        if j in sim_to_edu:\n","          i[idx_i] = '課業'\n","        elif j in sim_to_live:\n","          i[idx_i] = '生活'\n","        elif j not in top5:\n","          i[idx_i] = '其他'\n","    else:\n","      if i in sim_to_edu:\n","        y_data[idx] = '課業'\n","      elif i in sim_to_live:\n","        y_data[idx] = '生活'\n","      elif i not in top5:\n","        y_data[idx] = '其他'\n","\n","  # transfer the label to one-hot-encoding vector\n","  result = []\n","  encoding_label = ['課業', '蓋樓', '生活', '問題', '食物', '其他']\n","  for i in y_data:\n","    encoding_arr = np.zeros(6)\n","    if type(i) is list:\n","        for j in i:\n","            encoding_arr[encoding_label.index(j)] = 1\n","    else:\n","        encoding_arr[encoding_label.index(i)] = 1\n","    result.append(encoding_arr)\n","\n","  return result"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"dZzhAs7Ti-wI"},"source":["# DataSet"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"6dSTAdeE2LB2"},"source":["## DataSet Define"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3G3W1uX5R61q"},"outputs":[],"source":["class Dataset():\n","  def __init__(self, Content, Label, num):\n","    self.x = Content\n","    self.y = Label\n","    self.n_samples = num\n","\n","  # working for indexing\n","  def __getitem__(self, index):\n","    return self.x[index], self.y[index]\n","\n","  # return the length of our dataset\n","  def __len__(self):\n","    return self.n_samples\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"NbIT0gt2jGpJ"},"source":["## DataSet create"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hkVBKtchXw5n"},"outputs":[],"source":["# load CSV\n","df = pd.read_csv('NCU_dataset.csv')\n","content = df['content'].tolist()\n","\n","# do one-hot-encoding for label\n","label = OneHotEncoding(df['sentiment'])\n","\n","# split dataset\n","x_train, x_test, y_train, y_test = train_test_split(content, label, test_size=0.3, random_state=1)\n","\n","# replace the empty of content with 'No Content'\n","for i in range(len(x_train)):\n","  if type(x_train[i]) is float:\n","    x_train[i] = 'No Content'\n","\n","for i in range(len(x_test)):\n","  if type(x_test[i]) is float:\n","    x_test[i] = 'No Content'\n","\n","# create train and test dataset\n","train_set = Dataset(x_train, y_train, len(x_train))\n","test_set = Dataset(x_test, y_test, len(x_test))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"4JRLR8gwjZVb"},"source":["## DataLoader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HA3M32tXZxHU"},"outputs":[],"source":["train_dataloader = DataLoader(dataset=train_set, batch_size=16, shuffle=True)\n","test_dataloader = DataLoader(dataset=test_set, batch_size=16, shuffle=True)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"cH4mn5gj0JNT"},"source":["# Model\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"qdg5ASMsKXq0"},"source":["## import package"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e4ZP9Z941Hso"},"outputs":[],"source":["from transformers import BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup,  BertTokenizer\n","import torch.nn as nn\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"msfdY5T-TaFU"},"source":["## Use GPU"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NYzekKipTfE-"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"dUjdDaPy2AwW"},"source":["## Hyper Paramaters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lf4ZtJ2Y19iy"},"outputs":[],"source":["epoch = 10\n","learnrate = 1e-4"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"wMZKU9bB2ESz"},"source":["## Model Define"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":190,"referenced_widgets":["15a0d7396b104c57b2976eee5c8d9289","eefe4363733e4a11a686acd7ab441dca","c80cc1588d8b4af6addd88ee952aac64","1dc04d49c906462f87318616191eaf79","4826affc8c204d03a3bef6b1b40c16f7","257445e396f34d42afd91ce7348bff13","33d2739f495d4eb1b118e67fb97c0d75","c29416bb24a541e2aa6f9529ed8467d6","b5e9ecbd591e40a198a9956b131e8b71","4a072dfdb00d40a3a08defd9320c5c2c","e12c48be2a4c49bcb29a14182d69e4a5"]},"executionInfo":{"elapsed":13301,"status":"ok","timestamp":1678978262793,"user":{"displayName":"林宥騰","userId":"01208095819161324571"},"user_tz":-480},"id":"rg9E5XowqjQf","outputId":"722de219-c6ef-42f0-84df-378b54eae2ea"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"15a0d7396b104c57b2976eee5c8d9289","version_major":2,"version_minor":0},"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/412M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}],"source":["# Define model\n","model = BertForSequenceClassification.from_pretrained('bert-base-chinese', num_labels=6)\n","model.to(device)\n","\n","# Define tokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n","\n","# Define optimizer\n","optim = AdamW(model.parameters(), lr=learnrate)\n","\n","# Define Loss function\n","criterion = nn.BCEWithLogitsLoss()\n","\n","# Use Warm_up\n","total_steps = len(train_dataloader) * epoch\n","scheduler = get_linear_schedule_with_warmup(optim, num_warmup_steps = 0, num_training_steps = total_steps)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"DQNgByNN_cqD"},"source":["# Training Function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n9n4yXL3_cD9"},"outputs":[],"source":["def train(model, iterator, optimizer, criterion, total, device):\n","  model.train()\n","  train_loss = 0\n","  for batch_idx, (sentences, labels) in enumerate(iterator):\n","    # tokenize the sentences\n","    encoding = tokenizer(sentences, return_tensors='pt', padding=True, truncation=True)\n","    input_ids = encoding['input_ids']\n","    attention_mask = encoding['attention_mask']\n","\n","    # move to GPU\n","    input_ids, labels , attention_mask = input_ids.to(device), labels.to(device), attention_mask.to(device)\n","\n","    # generate prediction\n","    optimizer.zero_grad()\n","    outputs = model(input_ids, attention_mask=attention_mask, labels = labels)\n","\n","    # compute gradients and accumulate train loss\n","    loss = criterion(outputs.logits, labels) # BCEWithLogitsLoss has sigmoid\n","    train_loss += loss\n","\n","    # 反向梯度信息\n","    loss.backward()\n","\n","    # 梯度截斷，處理梯度爆炸\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","    # 參數更新\n","    optimizer.step()\n","    scheduler.step()\n","\n","  # print completed result\n","  print('train_loss: %f' % (train_loss))\n","  print(scheduler.get_last_lr())\n","  return train_loss"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Gxqi4gdKCthD"},"source":["# Testing Function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q1u0I41RDLOG"},"outputs":[],"source":["def test(model, iterator, optimizer, criterion, total, device):\n","  model.eval()\n","\n","  with torch.no_grad():\n","    acc_batch = 0\n","    tp = [0]*6\n","    fp = [0]*6\n","    fn = [0]*6\n","    tn = [0]*6\n","    for batch_idx, (sentences, labels) in enumerate(iterator):\n","\n","      # tokenize the sentences\n","      encoding = tokenizer(sentences, return_tensors='pt', padding=True, truncation=True)\n","      input_ids = encoding['input_ids']\n","      attention_mask = encoding['attention_mask']\n","\n","      # move to GPU\n","      input_ids, labels , attention_mask = input_ids.to(device), labels.to(device), attention_mask.to(device)\n","\n","      # generate prediction\n","      outputs = model(input_ids, attention_mask=attention_mask)\n","      prob = outputs.logits.sigmoid()\n","\n","      # translate the prediction to 0 or 1\n","      THRESHOLD = 0.3\n","      predicition = prob.detach().clone()\n","      predicition[predicition > THRESHOLD] = 1\n","      predicition[predicition <= THRESHOLD] = 0\n","\n","      # calculate the accuracy\n","      # the acc_batch result is the accuracy of one batch\n","      acc_batch += acc_calculate(predicition, labels)\n","\n","      # confusion matrix\n","      CMC(tp, fp, fn, tn, predicition, labels)\n","\n","  # got accuracy of total by divide acc_batch with the length of testdata size\n","  acc = acc_batch/total\n","\n","  # calculate recall and precision\n","  precision = []\n","  recall = []\n","  for i in range(6):\n","    if tp[i]+fp[i] != 0:\n","      precision.append(tp[i]/(tp[i]+fp[i]))\n","    else:\n","      precision.append(0)\n","\n","    if tp[i]+fn[i] != 0:\n","      recall.append(tp[i]/(tp[i]+fn[i]))\n","    else:\n","      recall.append(0)\n","\n","  # print the result\n","  encoding_label = ['課業', '蓋樓', '生活', '問題', '食物', '其他']\n","  print('test_acc: %f' % (acc))\n","  for i in range(len(encoding_label)):\n","    print('%s precision: %f recall: %f' % (encoding_label[i], precision[i], recall[i]))\n","\n","  return acc\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"o9JzlI_36-Mq"},"source":["## Acc Calculate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n8NdPiST7Dnv"},"outputs":[],"source":["def acc_calculate(preds, labels):\n","  correct = 0\n","  for pred, label in zip(preds, labels):\n","    union = 0\n","    inter = 0\n","    for i in range(len(pred)):\n","      if pred[i] == 1 and label[i] == 1:\n","        inter += 1\n","      if pred[i] == 1 or label[i] == 1:\n","        union += 1\n","    correct += (inter/union)\n","  return correct\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"gWjh6iIF2ohg"},"source":["## Confusion Matrix Calculate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cm9e1n8j2nwl"},"outputs":[],"source":["# 課業, 蓋樓, 生活, 問題, 食物, 其他\n","def CMC(tp, fp, fn, tn, preds, labels):\n","  for pred, label in zip(preds, labels):\n","    for i in range(len(label)):\n","      if pred[i] == 0 and label[i] == 0:\n","        fn[i] += 1\n","      if pred[i] == 0 and label[i] == 1:\n","        tn[i] += 1\n","      if pred[i] == 1 and label[i] == 0:\n","        fp[i] += 1\n","      if pred[i] == 1 and label[i] == 1:\n","        tp[i] += 1"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Cnleo1CcJ6Xw"},"source":["# Start Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1108681,"status":"ok","timestamp":1678979371455,"user":{"displayName":"林宥騰","userId":"01208095819161324571"},"user_tz":-480},"id":"4EAkQ_n4KofC","outputId":"77be1432-2f70-48f7-a425-ee09a37d36d5"},"outputs":[{"name":"stdout","output_type":"stream","text":["===== Epoch 0 =====\n","Training started ...\n","train_loss: 103.401580\n","[9e-05]\n","Testing started ...\n","test_acc: 0.791932\n","課業 precision: 0.817857 recall: 0.282716\n","蓋樓 precision: 0.936925 recall: 0.272866\n","生活 precision: 0.759442 recall: 0.612752\n","問題 precision: 0.839506 recall: 0.135404\n","食物 precision: 0.864706 recall: 0.114441\n","其他 precision: 0.682243 recall: 0.029142\n","===== Epoch 1 =====\n","Training started ...\n","train_loss: 66.815268\n","[8e-05]\n","Testing started ...\n","test_acc: 0.807625\n","課業 precision: 0.815436 recall: 0.296341\n","蓋樓 precision: 0.952000 recall: 0.271896\n","生活 precision: 0.782819 recall: 0.594943\n","問題 precision: 0.760314 recall: 0.154738\n","食物 precision: 0.868098 recall: 0.110504\n","其他 precision: 0.619883 recall: 0.042282\n","===== Epoch 2 =====\n","Training started ...\n","train_loss: 50.251184\n","[7e-05]\n","Testing started ...\n","test_acc: 0.823662\n","課業 precision: 0.871698 recall: 0.278649\n","蓋樓 precision: 0.959294 recall: 0.269333\n","生活 precision: 0.834862 recall: 0.563218\n","問題 precision: 0.766791 recall: 0.162966\n","食物 precision: 0.802993 recall: 0.125585\n","其他 precision: 0.526104 recall: 0.052844\n","===== Epoch 3 =====\n","Training started ...\n","train_loss: 37.719595\n","[6e-05]\n","Testing started ...\n","test_acc: 0.822070\n","課業 precision: 0.844340 recall: 0.288710\n","蓋樓 precision: 0.960705 recall: 0.269787\n","生活 precision: 0.797164 recall: 0.586661\n","問題 precision: 0.824675 recall: 0.150237\n","食物 precision: 0.840000 recall: 0.122283\n","其他 precision: 0.651685 recall: 0.046032\n","===== Epoch 4 =====\n","Training started ...\n","train_loss: 28.521754\n","[5e-05]\n","Testing started ...\n","test_acc: 0.814957\n","課業 precision: 0.789530 recall: 0.303117\n","蓋樓 precision: 0.953020 recall: 0.270682\n","生活 precision: 0.843031 recall: 0.552795\n","問題 precision: 0.745318 recall: 0.159327\n","食物 precision: 0.781176 recall: 0.129688\n","其他 precision: 0.684211 recall: 0.041237\n","===== Epoch 5 =====\n","Training started ...\n","train_loss: 21.122349\n","[4e-05]\n","Testing started ...\n","test_acc: 0.826962\n","課業 precision: 0.829545 recall: 0.294830\n","蓋樓 precision: 0.950336 recall: 0.270332\n","生活 precision: 0.822923 recall: 0.569773\n","問題 precision: 0.843267 recall: 0.149980\n","食物 precision: 0.821608 recall: 0.126892\n","其他 precision: 0.643750 recall: 0.041003\n","===== Epoch 6 =====\n","Training started ...\n","train_loss: 14.305996\n","[3e-05]\n","Testing started ...\n","test_acc: 0.829589\n","課業 precision: 0.853047 recall: 0.287093\n","蓋樓 precision: 0.958277 recall: 0.270825\n","生活 precision: 0.811029 recall: 0.583333\n","問題 precision: 0.804878 recall: 0.156151\n","食物 precision: 0.827411 recall: 0.126406\n","其他 precision: 0.593909 recall: 0.046744\n","===== Epoch 7 =====\n","Training started ...\n","train_loss: 8.901821\n","[2e-05]\n","Testing started ...\n","test_acc: 0.835018\n","課業 precision: 0.858173 recall: 0.286517\n","蓋樓 precision: 0.956757 recall: 0.269817\n","生活 precision: 0.838120 recall: 0.564148\n","問題 precision: 0.834783 recall: 0.150943\n","食物 precision: 0.865014 recall: 0.121423\n","其他 precision: 0.582960 recall: 0.051938\n","===== Epoch 8 =====\n","Training started ...\n","train_loss: 6.098551\n","[1e-05]\n","Testing started ...\n","test_acc: 0.836796\n","課業 precision: 0.843458 recall: 0.290660\n","蓋樓 precision: 0.958277 recall: 0.270825\n","生活 precision: 0.838501 recall: 0.567308\n","問題 precision: 0.819533 recall: 0.152148\n","食物 precision: 0.831202 recall: 0.125969\n","其他 precision: 0.615000 recall: 0.048965\n","===== Epoch 9 =====\n","Training started ...\n","train_loss: 4.401736\n","[0.0]\n","Testing started ...\n","test_acc: 0.834924\n","課業 precision: 0.850356 recall: 0.288013\n","蓋樓 precision: 0.958277 recall: 0.270825\n","生活 precision: 0.849031 recall: 0.556236\n","問題 precision: 0.829374 recall: 0.151122\n","食物 precision: 0.841558 recall: 0.125387\n","其他 precision: 0.576577 recall: 0.051200\n"]}],"source":["for e in range(epoch):\n","\n","  print(\"===== Epoch %i =====\" % e)\n","\n","  # training\n","  print(\"Training started ...\")\n","  train(model, train_dataloader, optim, criterion, len(train_dataloader), device)\n","\n","  # validation testing\n","  print(\"Testing started ...\")\n","  test(model, test_dataloader, optim, criterion, len(x_test), device)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"su3XezIPItDi"},"source":["# Save Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xEXoegIDIsyl"},"outputs":[],"source":["name = 'Bahamut_NCU.pt'\n","path = F\"/content/drive/MyDrive/專題/{name}\"\n","torch.save(model, path)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNIV2yD9A7IHzAaeh3YfZ8A","mount_file_id":"1GcWdtI-IWHovjAoKhURGR0gMtcj5kdV4","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"15a0d7396b104c57b2976eee5c8d9289":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eefe4363733e4a11a686acd7ab441dca","IPY_MODEL_c80cc1588d8b4af6addd88ee952aac64","IPY_MODEL_1dc04d49c906462f87318616191eaf79"],"layout":"IPY_MODEL_4826affc8c204d03a3bef6b1b40c16f7"}},"1dc04d49c906462f87318616191eaf79":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a072dfdb00d40a3a08defd9320c5c2c","placeholder":"​","style":"IPY_MODEL_e12c48be2a4c49bcb29a14182d69e4a5","value":" 412M/412M [00:05&lt;00:00, 69.5MB/s]"}},"257445e396f34d42afd91ce7348bff13":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33d2739f495d4eb1b118e67fb97c0d75":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4826affc8c204d03a3bef6b1b40c16f7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a072dfdb00d40a3a08defd9320c5c2c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5e9ecbd591e40a198a9956b131e8b71":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c29416bb24a541e2aa6f9529ed8467d6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c80cc1588d8b4af6addd88ee952aac64":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c29416bb24a541e2aa6f9529ed8467d6","max":411577189,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b5e9ecbd591e40a198a9956b131e8b71","value":411577189}},"e12c48be2a4c49bcb29a14182d69e4a5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eefe4363733e4a11a686acd7ab441dca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_257445e396f34d42afd91ce7348bff13","placeholder":"​","style":"IPY_MODEL_33d2739f495d4eb1b118e67fb97c0d75","value":"Downloading pytorch_model.bin: 100%"}}}}},"nbformat":4,"nbformat_minor":0}
